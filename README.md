# ğŸ¤– Personal AI Chatbot with RAG-Based Memory

A fully offline, privacy-first AI chatbot with **long-term memory**, **user profiles**, and **context-aware responses** â€” powered by **local LLMs** and a **retrieval-augmented generation (RAG)** system using FAISS.

Inspired by ChatGPT â€” but runs **completely on your machine**, with **zero cloud dependency**.

---

## ğŸš€ Features

- ğŸ§  **RAG Memory**: Retrieves relevant past info via vector embeddings (FAISS)
- ğŸ’¬ Natural chat flow using local LLMs (Mixtral, Mistral, LLaMA, etc.)
- ğŸ‘¤ Personalized context memory (name, interests, routines)
- ğŸ“ Automatic session summarization with title generation
- ğŸ“‚ Fully local JSON storage for chats, summaries, and profiles
- ğŸ–¥ï¸ LM Studio integration for model serving (OpenAI-compatible API)

---

## ğŸ› ï¸ Requirements

- Python 3.10+
- [LM Studio](https://lmstudio.ai) running locally
- Install dependencies:

```bash
pip install -r requirements.txt
````

---

## ğŸ¤– Local LLM Setup

1. **Install LM Studio**
2. **Download a compatible model** (e.g.):

   * `mixtral-8x7b-instruct-v0.1.Q4_K_M`
   * `Nous-Hermes-2-Mistral-7B-DPO`
3. **Start LM Studioâ€™s OpenAI API Server**:

   * `http://localhost:1234/v1/chat/completions`

---

## ğŸ§  Memory System

* âœ… **RAG Engine** (`rag/`):

  * Uses SentenceTransformers to embed messages & summaries
  * Stores in FAISS vector index
  * Retrieves top-k context chunks per user query

* âœ… **Summarization** (`memory.py`):

  * Generates structured summaries using LLM
  * Saved and injected into memory on startup

* âœ… **User Profile**:

  * Name, preferences, and key traits saved locally

---

## ğŸ“‚ Project Structure

```
chat_sessions/             â† Chat logs, summaries, and user profile
rag/                       â† Embedder, VectorStore, and RAGEngine modules
main.py                    â† CLI entrypoint with chat + RAG + memory
memory.py                  â† Session, summary, and profile logic
requirements.txt           â† Python dependencies
```

> All volatile data (chats, vector DB, profiles) is excluded via `.gitignore`

---

## â–¶ï¸ Run the Chatbot

```bash
python main.py
```

Youâ€™ll see:

```
ğŸ¤– Personal AI Chatbot with RAG memory is running! Type 'exit' to quit.
```

---

## ğŸ’¬ Example Memory Recall

```
You: My dog's name is Pluto.
You: I love the movie Interstellar.
You: I'm building a skincare app.
...
You: What's my dog's name?
Bot: You mentioned your dog's name is Pluto.
```

---

## ğŸ” Privacy First

This bot runs **100% offline**. No cloud, no tracking, no data leaks.
All chat and memory are stored **locally on your device**.

---

## ğŸ§© Future Improvements

* Web frontend (Next.js + FastAPI API)
* Session renaming + metadata UI
* Embedding cache for faster boot
* Multi-user login
* Gradio or Tkinter UI

---

## ğŸ‘¨â€ğŸ’» Author

Built with â¤ï¸ by [Gaurav](https://github.com/Gaurav8302)
MIT Licensed Â· Powered by Open Source LLMs

```

---

### âœ… Whatâ€™s New
- Added `rag/` structure
- Described FAISS RAG pipeline
- Updated run instructions
- Future roadmap and privacy note
- GitHub-friendly formatting

Let me know if you'd like a version with screenshots or badges next!
```
